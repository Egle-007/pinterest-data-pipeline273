{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IAM: 0e172e8c4bc3-ec2-access-role arn:aws:iam::584739742957:role/0e172e8c4bc3-ec2-access-role\n",
    "# MSK ARN: arn:aws:kafka:us-east-1:584739742957:cluster/pinterest-msk-cluster/afed8c1a-6313-4117-857f-7fac4b340aab-12\n",
    "\n",
    "# MSK bootstrap server string: \n",
    "# b-1.pinterestmskcluster.w8g8jt.c12.kafka.us-east-1.amazonaws.com:9098,b-2.pinterestmskcluster.w8g8jt.c12.kafka.us-east-1.amazonaws.com:9098,b-3.pinterestmskcluster.w8g8jt.c12.kafka.us-east-1.amazonaws.com:9098\n",
    "\n",
    "# MSK plaintext zookeeper string: \n",
    "# z-2.pinterestmskcluster.w8g8jt.c12.kafka.us-east-1.amazonaws.com:2181,z-1.pinterestmskcluster.w8g8jt.c12.kafka.us-east-1.amazonaws.com:2181,z-3.pinterestmskcluster.w8g8jt.c12.kafka.us-east-1.amazonaws.com:2181\n",
    "\n",
    "# Username: 0e172e8c4bc3\n",
    "\n",
    "# topics:\n",
    "# 0e172e8c4bc3.pin, 0e172e8c4bc3.geo, 0e172e8c4bc3.user\n",
    "./kafka-topics.sh --bootstrap-server b-1.pinterestmskcluster.w8g8jt.c12.kafka.us-east-1.amazonaws.com:9098,b-2.pinterestmskcluster.w8g8jt.c12.kafka.us-east-1.amazonaws.com:9098,b-3.pinterestmskcluster.w8g8jt.c12.kafka.us-east-1.amazonaws.com:9098 --command-config client.properties --create --topic 0e172e8c4bc3.pin\n",
    "\n",
    "# assume admin user privileges\n",
    "sudo -u ec2-user -i\n",
    "# create directory where we will save our connector \n",
    "mkdir kafka-connect-s3 && cd kafka-connect-s3\n",
    "# download connector from Confluent\n",
    "wget https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-s3/versions/10.0.3/confluentinc-kafka-connect-s3-10.0.3.zip\n",
    "# copy connector to our S3 bucket\n",
    "aws s3 cp ./confluentinc-kafka-connect-s3-10.0.3.zip s3://user-0e172e8c4bc3-bucket/kafka-connect-s3/\n",
    "\n",
    "# MSK connect\n",
    "# 0e172e8c4bc3-plugin, 0e172e8c4bc3-connector\n",
    "\n",
    "# Kafka REST API. invoke API after deployment: https://afm0un5nrb.execute-api.us-east-1.amazonaws.com/PDP-Mile-5-Step-3\n",
    "\n",
    "# KINESIS invoke URL \n",
    "https://afm0un5nrb.execute-api.us-east-1.amazonaws.com/PDP-Mile-9-Task-2\n",
    "\n",
    "# Starting the REST proxy. Navigate to the confluent-7.2.0/bin folder, and then run the following command:\n",
    "./kafka-rest-start /home/ec2-user/confluent-7.2.0/etc/kafka-rest/kafka-rest.properties\n",
    "\n",
    "# EC2: ssh -i \"0e172e8c4bc3-key-pair.pem\" ec2-user@ec2-3-90-60-74.compute-1.amazonaws.com\n",
    "\n",
    "\n",
    "# So that pin_string is the sql for extracting the info from the external table. After its been extracted (which will be a line like pin_result = dict(row)) for each topic you will want to:\n",
    "# set a variable for the invoke url changing the endpoint to the correct topic\n",
    "# create the payload as strtuctured in the notebook - you should change the dictionary in the \"value\" key to have a dictionary of the data you'll be sending - we're essentially telling the api how the data will be structured in this step\n",
    "# for the timestamp columns (only in the geo and user data) you can create a function to covert the column data to either a string or iso format which will allow the data to be sent\n",
    "# Try sending the request\n",
    "\n",
    "\n",
    "# producer :\n",
    "./kafka-console-producer.sh --bootstrap-server b-1.pinterestmskcluster.w8g8jt.c12.kafka.us-east-1.amazonaws.com:9098,b-2.pinterestmskcluster.w8g8jt.c12.kafka.us-east-1.amazonaws.com:9098,b-3.pinterestmskcluster.w8g8jt.c12.kafka.us-east-1.amazonaws.com:9098 --producer.config client.properties --group students --topic 0e172e8c4bc3.pin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi, \n",
    "\n",
    "Happy new year, hope you are well. \n",
    "\n",
    "I am writing to ask about this task: mile5, task3 step2: \"Check data is sent to the cluster by running a Kafka consumer (one per topic). If everything has been set up correctly, you should see messages being consumed.\"\n",
    "\n",
    "1. Do I need to do this step if I can see what is in the step 3? \n",
    "2. When I tried to create producer according to this notebook: https://colab.research.google.com/github/AI-Core/Content-Public/blob/main/Content/units/Cloud-and-DevOps/3.%20Essential%20Cloud%20Technology/10.%20MSK%20Essentials/Notebook.ipynb\n",
    "Create & run a producer and a consumer section, I got an error \"group is not a recognized option\"\n",
    "\n",
    "./kafka-console-producer.sh --bootstrap-server b-1.pinterestmskcluster.w8g8jt.c12.kafka.us-east-1.amazonaws.com:9098,b-2.pinterestmskcluster.w8g8jt.c12.kafka.us-east-1.amazonaws.com:9098,b-3.pinterestmskcluster.w8g8jt.c12.kafka.us-east-1.amazonaws.com:9098 --producer.config client.properties --group students --topic 0e172e8c4bc3.pin\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
